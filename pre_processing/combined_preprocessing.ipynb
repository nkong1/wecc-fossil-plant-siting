{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b587575b",
   "metadata": {},
   "source": [
    "This script further processes the initial 1x1km suitability layers of each hydrogen production technology. The steps are as follows:\n",
    "1) The 1x1km features are broken down into sizes corresponding to the reference plant footprint of each production technology.\n",
    "\n",
    "2) A high geospatial resolution filter (30m) is applied using the NLCD and Farms Under Threat datasets.\n",
    "\n",
    "3) Candidates that do not fall squarely within a load zone are removed.\n",
    "\n",
    "4) ** Requires manual intervention ** Export the intermediate outputs from Step 3 to pgAdmin and use Postgres to add distances to feedstock sources and substations using the script in the 'postgres' folder. Put outputs in the folder 'candidate_sites_with_dists'\n",
    "\n",
    "5) Remove candidate sites that overlap with substations or above-ground feedstock sources (an overlap with a natural gas pipelines is allowed because these are typically located underground, but an overlap with a biogas plant is not)\n",
    "\n",
    "6) Overlaps between technologies are resolved by grouping the candidate layers and iteratively filtering them in order of increasing candidate count, so that sites from sparser layers are preserved at a higher proportion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441d725",
   "metadata": {},
   "source": [
    "Set-Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ca92c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and methods\n",
    "\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rasterio.features import geometry_mask\n",
    "from rasterio.windows import from_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "233ab36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data paths\n",
    "base_path = Path.cwd() # this is the pre-processing folder path\n",
    "\n",
    "# Input data paths\n",
    "candidate_sites_path = base_path / 'input_files' / \"candidate_sites_1x1km\"\n",
    "combined_exclusion_30m_path = base_path / 'input_files' / 'combined_exclusion_30m.tif'\n",
    "load_zones_path = base_path / \"input_files\" / \"load_zones\" / \"load_zones.shp\"\n",
    "\n",
    "# Intermediate output paths\n",
    "ref_footprints_output_path = base_path / 'intermediate_outputs' / 'ref_footprints' \n",
    "filtered_nlcd_ag_path = base_path / 'intermediate_outputs' / 'nlcd_ag_filtered'\n",
    "with_dists_path = base_path / 'intermediate_outputs' / 'with_dists'\n",
    "infrastructure_overlaps_removed_path = base_path / 'intermediate_outputs' / 'no_infrastructure_overlaps'\n",
    "\n",
    "# Final output path for suitable candidate sites\n",
    "final_output_path = base_path.parent / 'candidate_sites'\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "for path in [ref_footprints_output_path, filtered_nlcd_ag_path, with_dists_path, infrastructure_overlaps_removed_path, final_output_path]:\n",
    "    path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05062e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reference plant specifications\n",
    "\n",
    "# Create a dictionary mapping each hydrogen production technology to its square reference plant footprint length (m)\n",
    "ref_footprint = {\n",
    "    \"gas_smr\": 354.5,\n",
    "    \"gas_smr_ccs\": 354.5,\n",
    "    \"bio_smr\": 354.5,\n",
    "    \"bio_smr_ccs\": 354.5,\n",
    "    \"gas_atr_ccs\": 354.5,\n",
    "    \"bio_atr_ccs\": 354.5,\n",
    "    \"coal_gas\": 614.0,\n",
    "    \"coal_gas_ccs\": 614.0,\n",
    "    \"biomass_gas\": 297.6,\n",
    "}\n",
    "\n",
    "# Create a dictionary mapping each hydrogen production technology to its reference plant capacity (tonnes/day)\n",
    "ref_capacity = {\n",
    "    \"gas_smr\": 150,\n",
    "    \"gas_smr_ccs\": 150,\n",
    "    \"bio_smr\": 150,\n",
    "    \"bio_smr_ccs\": 150,\n",
    "    \"gas_atr_ccs\": 205,\n",
    "    \"bio_atr_ccs\": 205,\n",
    "    \"coal_gas\": 205,\n",
    "    \"coal_gas_ccs\": 205,\n",
    "    \"biomass_gas\": 48,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f7cc46",
   "metadata": {},
   "source": [
    "Step 1: Break down each 1x1km suitable square into smaller squares based on the reference plant footprint lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59f593f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function that a length (in meters) to the nearest length greater than or equal to the original length that evenly divide a \n",
    "# 1x1 km grid into squares.\n",
    "\n",
    "def nearest(length):\n",
    "    if length <= 250:\n",
    "        return 250\n",
    "    elif length <= 1000/3:\n",
    "        return 1000/3\n",
    "    elif length <= 500:\n",
    "        return 500\n",
    "    elif length <= 1000:\n",
    "        return 1000\n",
    "\n",
    "# Use the helper to map the reference footprint length for each tech to the length we'll use to break down the 1x1km squares.\n",
    "rounded_ref_capacity = {k: nearest(v) for k, v in ref_footprint.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef4c6b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: biomass_gas.gpkg\n",
      "Processed sites with reference footprints for biomass_gas.\n",
      "Processing: gas_atr_ccs.gpkg\n",
      "Processed sites with reference footprints for gas_atr_ccs.\n",
      "Processing: coal_gas_ccs.gpkg\n",
      "Processed sites with reference footprints for coal_gas_ccs.\n",
      "Processing: bio_atr_ccs.gpkg\n",
      "Processed sites with reference footprints for bio_atr_ccs.\n",
      "Processing: gas_smr_ccs.gpkg\n",
      "Processed sites with reference footprints for gas_smr_ccs.\n",
      "Processing: bio_smr_ccs.gpkg\n",
      "Processed sites with reference footprints for bio_smr_ccs.\n",
      "Processing: bio_smr.gpkg\n",
      "Processed sites with reference footprints for bio_smr.\n",
      "Processing: coal_gas.gpkg\n",
      "Processed sites with reference footprints for coal_gas.\n",
      "Processing: gas_smr.gpkg\n",
      "Processed sites with reference footprints for gas_smr.\n"
     ]
    }
   ],
   "source": [
    "# Run processing\n",
    "for file_path in candidate_sites_path.glob(\"*.gpkg\"):\n",
    "    print('Processing:', file_path.name)\n",
    "    # Extract the technology name from the file name\n",
    "    tech_name = file_path.stem\n",
    "    \n",
    "    # Load the candidate sites GeoPackage\n",
    "    gdf = gpd.read_file(file_path)\n",
    "    \n",
    "    # Get the reference plant footprint length for the current technology\n",
    "    ref_length = rounded_ref_capacity.get(tech_name)\n",
    "    \n",
    "    # Calculate the number of smaller squares along each side of the 1x1 km square\n",
    "    num_squares_per_side = int(1000 / ref_length)\n",
    "    \n",
    "    suitable_sites = []\n",
    "    \n",
    "    # Iterate over each geometry in the GeoDataFrame\n",
    "    for _, row in gdf.iterrows():\n",
    "\n",
    "        minx, miny, maxx, maxy = row.geometry.bounds\n",
    "        \n",
    "        # Generate smaller squares within the 1x1 km square\n",
    "        for i in range(num_squares_per_side):\n",
    "            for j in range(num_squares_per_side):\n",
    "                new_minx = minx + i * ref_length\n",
    "                new_miny = miny + j * ref_length\n",
    "                new_maxx = new_minx + ref_length\n",
    "                new_maxy = new_miny + ref_length\n",
    "                \n",
    "                new_square = box(new_minx, new_miny, new_maxx, new_maxy)\n",
    "                suitable_sites.append(new_square)\n",
    "    \n",
    "    # Create a GeoDataFrame from the suitable sites\n",
    "    suitable_gdf = gpd.GeoDataFrame(geometry=suitable_sites, crs=gdf.crs)\n",
    "                      \n",
    "    suitable_gdf.to_file(ref_footprints_output_path / f\"{tech_name}.gpkg\", driver=\"GPKG\")\n",
    "    \n",
    "    print(f\"Processed sites with reference footprints for {tech_name}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b5e9a",
   "metadata": {},
   "source": [
    "Step 2: Apply the NLCD and Farms Under Threat datasets (each has a 30m resolution) to filter the candidates in the newly obtained layers. \n",
    "\n",
    "Using the NLCD, we filter out: Open Water, Pernnial Ice/Snow, Developed Open Space, Developed Low Intensity, Developed Medium Intensity, Developed High Intensity, Deciduous Forest, Evergreen Forest, Mixed Forest, Woody Wetlands, and Herbaceous Wetlands.\n",
    "\n",
    "Using the Farms under Threat dataset, we filter out \"Nationally Significant Agricultural Land.\"\n",
    "\n",
    "For ease of processing, we combined the two datasets into one raster file. Excluded pixels have a value of 1.\n",
    "\n",
    "Note: If 95% or more of a candidate site passes the filter, it is deemed acceptable and kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b5674a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper function to calculate the acceptance of a candidate site using an exclusion raster\n",
    "def calculate_acceptance(geometry, exclusion_src, threshold=0.95):\n",
    "    # Get bounding box\n",
    "    minx, miny, maxx, maxy = geometry.bounds\n",
    "    \n",
    "    # Compute window for each raster\n",
    "    exclusion_window = from_bounds(minx, miny, maxx, maxy, exclusion_src.transform)\n",
    "    \n",
    "    # Read only windowed data\n",
    "    exclusion_data = exclusion_src.read(1, window=exclusion_window)\n",
    "    \n",
    "    window_transform = exclusion_src.window_transform(exclusion_window)\n",
    "    mask = geometry_mask(\n",
    "        [geometry],\n",
    "        transform=window_transform,\n",
    "        invert=True,\n",
    "        out_shape=exclusion_data.shape,\n",
    "        all_touched=True\n",
    "    )\n",
    "\n",
    "    exclusion_window_values = exclusion_data[mask]\n",
    "    \n",
    "    valid_ratio = np.count_nonzero(exclusion_window_values == 0) / exclusion_window_values.size \n",
    "    return valid_ratio >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5e6f745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: biomass_gas.gpkg\n",
      "Saved filtered suitable sites for biomass_gas\n",
      "Processing: gas_atr_ccs.gpkg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m accepted_geometries \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m refined_gdf\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m calculate_acceptance(row\u001b[38;5;241m.\u001b[39mgeometry, exclusion_src):\n\u001b[1;32m     14\u001b[0m         accepted_geometries\u001b[38;5;241m.\u001b[39mappend(row\u001b[38;5;241m.\u001b[39mgeometry)\n\u001b[1;32m     16\u001b[0m final_gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(geometry\u001b[38;5;241m=\u001b[39maccepted_geometries, crs\u001b[38;5;241m=\u001b[39mrefined_gdf\u001b[38;5;241m.\u001b[39mcrs)\n",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m, in \u001b[0;36mcalculate_acceptance\u001b[0;34m(geometry, exclusion_src, threshold)\u001b[0m\n\u001b[1;32m     10\u001b[0m exclusion_data \u001b[38;5;241m=\u001b[39m exclusion_src\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m, window\u001b[38;5;241m=\u001b[39mexclusion_window)\n\u001b[1;32m     12\u001b[0m window_transform \u001b[38;5;241m=\u001b[39m exclusion_src\u001b[38;5;241m.\u001b[39mwindow_transform(exclusion_window)\n\u001b[0;32m---> 13\u001b[0m mask \u001b[38;5;241m=\u001b[39m geometry_mask(\n\u001b[1;32m     14\u001b[0m     [geometry],\n\u001b[1;32m     15\u001b[0m     transform\u001b[38;5;241m=\u001b[39mwindow_transform,\n\u001b[1;32m     16\u001b[0m     invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m     out_shape\u001b[38;5;241m=\u001b[39mexclusion_data\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     18\u001b[0m     all_touched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m exclusion_window_values \u001b[38;5;241m=\u001b[39m exclusion_data[mask]\n\u001b[1;32m     23\u001b[0m valid_ratio \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcount_nonzero(exclusion_window_values \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m exclusion_window_values\u001b[38;5;241m.\u001b[39msize \n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/rasterio/env.py:413\u001b[0m, in \u001b[0;36mensure_env.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Env\u001b[38;5;241m.\u001b[39mfrom_defaults():\n\u001b[0;32m--> 413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/rasterio/features.py:69\u001b[0m, in \u001b[0;36mgeometry_mask\u001b[0;34m(geometries, out_shape, transform, all_touched, invert)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a mask from shapes.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mBy default, mask is intended for use as a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m fill, mask_value \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m invert \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rasterize(\n\u001b[1;32m     70\u001b[0m     geometries,\n\u001b[1;32m     71\u001b[0m     out_shape\u001b[38;5;241m=\u001b[39mout_shape,\n\u001b[1;32m     72\u001b[0m     transform\u001b[38;5;241m=\u001b[39mtransform,\n\u001b[1;32m     73\u001b[0m     all_touched\u001b[38;5;241m=\u001b[39mall_touched,\n\u001b[1;32m     74\u001b[0m     fill\u001b[38;5;241m=\u001b[39mfill,\n\u001b[1;32m     75\u001b[0m     default_value\u001b[38;5;241m=\u001b[39mmask_value)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/rasterio/env.py:410\u001b[0m, in \u001b[0;36mensure_env.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local\u001b[38;5;241m.\u001b[39m_env:\n\u001b[0;32m--> 410\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m Env\u001b[38;5;241m.\u001b[39mfrom_defaults():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/rasterio/features.py:392\u001b[0m, in \u001b[0;36mrasterize\u001b[0;34m(shapes, out_shape, fill, nodata, masked, out, transform, all_touched, merge_alg, default_value, dtype, skip_invalid, dst_path, dst_kwds)\u001b[0m\n\u001b[1;32m    389\u001b[0m transform \u001b[38;5;241m=\u001b[39m guard_transform(transform)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_shapes:\n\u001b[0;32m--> 392\u001b[0m     _rasterize(valid_shapes, out, transform, all_touched, merge_alg)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m masked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32mrasterio/_features.pyx:384\u001b[0m, in \u001b[0;36mrasterio._features._rasterize\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_io.pyx:2254\u001b[0m, in \u001b[0;36mrasterio._io.MemoryDataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_io.pyx:2256\u001b[0m, in \u001b[0;36mrasterio._io.MemoryDataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/rasterio/env.py:316\u001b[0m, in \u001b[0;36mEnv.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_parent_env:\n\u001b[1;32m    315\u001b[0m     defenv()\n\u001b[0;32m--> 316\u001b[0m     setenv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_options)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExiting outermost env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/rasterio/env.py:359\u001b[0m, in \u001b[0;36msetenv\u001b[0;34m(**options)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EnvError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo GDAL environment exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     local\u001b[38;5;241m.\u001b[39m_env\u001b[38;5;241m.\u001b[39mupdate_config_options(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32mrasterio/_env.pyx:216\u001b[0m, in \u001b[0;36mrasterio._env.ConfigEnv.update_config_options\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_env.pyx:185\u001b[0m, in \u001b[0;36mrasterio._env.set_gdal_config\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:1483\u001b[0m, in \u001b[0;36mcurrent_thread\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join a dummy thread\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;66;03m# Global API functions\u001b[39;00m\n\u001b[0;32m-> 1483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_thread\u001b[39m():\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the current Thread object, corresponding to the caller's thread of control.\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m \n\u001b[1;32m   1486\u001b[0m \u001b[38;5;124;03m    If the caller's thread of control was not created through the threading\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;124;03m    module, a dummy thread object with limited functionality is returned.\u001b[39;00m\n\u001b[1;32m   1488\u001b[0m \n\u001b[1;32m   1489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Read in the exclusion raster\n",
    "exclusion_src = rasterio.open(combined_exclusion_30m_path)\n",
    "\n",
    "# Process each layer, using the intermediate files created in the previous step\n",
    "for file_path in ref_footprints_output_path.glob(\"*.gpkg\"):\n",
    "    print('Processing:', file_path.name)\n",
    "    tech_name = file_path.stem\n",
    "    \n",
    "    refined_gdf = gpd.read_file(file_path)\n",
    "    \n",
    "    accepted_geometries = []\n",
    "    for _, row in refined_gdf.iterrows():\n",
    "        if calculate_acceptance(row.geometry, exclusion_src):\n",
    "            accepted_geometries.append(row.geometry)\n",
    "    \n",
    "    final_gdf = gpd.GeoDataFrame(geometry=accepted_geometries, crs=refined_gdf.crs)\n",
    "    final_gdf.to_file(filtered_nlcd_ag_path / f\"{tech_name}.gpkg\", driver=\"GPKG\")\n",
    "    print(f\"Saved filtered suitable sites for {tech_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a580070",
   "metadata": {},
   "source": [
    "Step 3: Add a load area column to each file, filtering out candidates that do not fall squarely within a load zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the load zones file\n",
    "load_zones_gdf = gpd.read_file(load_zones_path)\n",
    "\n",
    "# Process each layer\n",
    "for file_path in filtered_nlcd_ag_path.glob(\"*.gpkg\"):\n",
    "    print('Processing:', file_path.name)\n",
    "    tech_name = file_path.stem\n",
    "    \n",
    "    final_gdf = gpd.read_file(file_path)\n",
    "    \n",
    "    # Perform spatial join to associate each candidate site with a load zone\n",
    "    joined_gdf = gpd.sjoin(final_gdf, load_zones_gdf[['geometry', 'LOAD_AREA']], how=\"left\", predicate=\"within\").reset_index(drop=True)\n",
    "    \n",
    "    # Filter out geometries that do not fall within any load zone\n",
    "    joined_gdf = joined_gdf[~joined_gdf[\"LOAD_AREA\"].isna()].copy().drop(columns=[\"index_right\"])\n",
    "\n",
    "    # Save the updated gdf back to the same file\n",
    "    joined_gdf.to_file(file_path, driver=\"GPKG\")\n",
    "    print(f\"Added load area info and saved for {tech_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761eaec",
   "metadata": {},
   "source": [
    "Step 4: Use PostgreSQL to add distances to feedstock sources and substations. Use the scripts in the 'postgres' folder. Put the resulting files in the folder 'candidate_sites_with_dists'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ad14b",
   "metadata": {},
   "source": [
    "Step 5: Remove overlaps with existing physical features (substations, coal mines, biomass plants, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d9642bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tech_file in with_dists_path.glob(\"*.gpkg\"):\n",
    "    tech_name = tech_file.stem\n",
    "    gdf = gpd.read_file(tech_file)\n",
    "\n",
    "    # Remove any candidate sites that overlap with substations\n",
    "    gdf = gdf[gdf[\"dist_to_substation_meters\"] > 0].copy()\n",
    "\n",
    "    # Remove any candidates that overlap with feedstock sources (except for natural gas, which may have pipelines underground)\n",
    "    if tech_name not in ['gas_smr', 'gas_smr_ccs', 'gas_atr_ccs']:\n",
    "        gdf = gdf[gdf[\"dist_to_feedstock_meters\"] > 0].copy()\n",
    "\n",
    "    gdf.to_file(infrastructure_overlaps_removed_path / f\"{tech_name}.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3200c",
   "metadata": {},
   "source": [
    "Step 6: Remove overlaps between the different technology layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af351a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a helper function to remove overlaps between layers\n",
    "def remove_overlaps(base_gdfs, top_gdf):\n",
    "    \"\"\"\n",
    "    Removes overlapping features from the top GeoDataFrame \n",
    "    where they overlap with the base GeoDataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    - base_gdf : A list of base layers (overlaps from top will be removed here).\n",
    "    - top_gdf : The top layer (features overlapping base will be removed).\n",
    "    \n",
    "    Returns\n",
    "    A GeoDataFrame consisting of:\n",
    "    - only the non-overlapping portions of features from top_gdf\n",
    "    \"\"\"\n",
    "    # Start with first base gdf, geometry only\n",
    "    combined_base = base_gdfs[0][[\"geometry\"]]\n",
    "\n",
    "    # Overlay the rest, geometry only\n",
    "    for base_gdf in base_gdfs[1:]:\n",
    "        combined_base = gpd.overlay(combined_base, base_gdf[[\"geometry\"]], how=\"union\")\n",
    "\n",
    "    # Spatial join to find overlapping top features\n",
    "    overlaps = gpd.sjoin(top_gdf, combined_base, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "    # Keep only those NOT in overlaps\n",
    "    cleaned_top = top_gdf.loc[~top_gdf.index.isin(overlaps.index)]\n",
    "    \n",
    "    return cleaned_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b5f6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the gdfs in order of increasing number of candidate sites\n",
    "biomass_gdf = gpd.read_file(infrastructure_overlaps_removed_path / 'biomass_gas.gpkg')\n",
    "bio_smr_gdf = gpd.read_file(infrastructure_overlaps_removed_path / 'bio_smr.gpkg')\n",
    "bio_smr_ccs_gdf = gpd.read_file(infrastructure_overlaps_removed_path / 'bio_smr_ccs.gpkg')\n",
    "coal_gas_ccs_gdf = gpd.read_file(infrastructure_overlaps_removed_path / 'coal_gas_ccs.gpkg')\n",
    "coal_gas_gdf = gpd.read_file(infrastructure_overlaps_removed_path / 'coal_gas.gpkg')\n",
    "gas_smr_gdf = gpd.read_file(infrastructure_overlaps_removed_path / 'gas_smr.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8991d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove overlaps in order of increasing number of candidate sites\n",
    "\n",
    "# The filtered sites for biomass are the same as the original\n",
    "biomass_gdf.to_file(final_output_path / 'biomass_gas.gpkg', driver='GPKG')\n",
    "\n",
    "# Get the combined sites for biomass smr and biomass smr + ccs\n",
    "all_bio_smr_gdf = remove_overlaps([biomass_gdf], bio_smr_ccs_gdf)\n",
    "all_bio_smr_gdf.to_file(final_output_path / 'all_bio_smr_atr.gpkg', driver='GPKG')\n",
    "\n",
    "# Get the sites for biomass smr + ccs only\n",
    "bio_smr_only_gdf = remove_overlaps([biomass_gdf, all_bio_smr_gdf], bio_smr_gdf)\n",
    "bio_smr_only_gdf.to_file(final_output_path / 'extra_bio_smr.gpkg', driver='GPKG')\n",
    "\n",
    "# Get the combined sites for coal gasification and coal gasification + ccs\n",
    "all_coal_gas_gdf = remove_overlaps([biomass_gdf, all_bio_smr_gdf, bio_smr_only_gdf], coal_gas_ccs_gdf)\n",
    "all_coal_gas_gdf.to_file(final_output_path / 'all_coal_gas.gpkg', driver='GPKG')\n",
    "\n",
    "# Get the sites for coal gasification + ccs only\n",
    "coal_gas_only_gdf = remove_overlaps([biomass_gdf, all_bio_smr_gdf, bio_smr_only_gdf, all_coal_gas_gdf], coal_gas_gdf)\n",
    "coal_gas_only_gdf.to_file(final_output_path / 'extra_coal_gas.gpkg', driver='GPKG')\n",
    "\n",
    "# Get the sites for all gas smr\n",
    "all_gas_smr_gdf = remove_overlaps([biomass_gdf, all_bio_smr_gdf, bio_smr_only_gdf, all_coal_gas_gdf, coal_gas_only_gdf], gas_smr_gdf)\n",
    "all_gas_smr_gdf.to_file(final_output_path / 'all_gas_smr_atr.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b6f6b",
   "metadata": {},
   "source": [
    "Step 7: Calculate the potential of each technology in each load zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32744342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create helper function that calculates the potential capacity per load zone for given tech(s)\n",
    "def calculate_potential(candidates_gdf, tech_names, ref_capacity):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    - candidates_gdf: the gdf of candidate sites for the given tech(s)\n",
    "    - tech_names: the hydrogen production technologies that the layer is for\n",
    "    - ref_capacity: the reference capacity of the candidates (tonnes/day)\n",
    "        - each technology in tech_names must have the same reference capacity\n",
    "\n",
    "    Outputs:\n",
    "    - df: a df with the potential capacity per tech by load zone, structured with the following columns:\n",
    "        - LOAD_AREA, prod_tech1, prod_tech2, prod_tech3, site_count, potential_MW\n",
    "        - prod_tech2 and prod_tech3 may be empty (contain empty strings)\n",
    "    \"\"\"\n",
    "\n",
    "    # Count the number of candidate sites in each load zone\n",
    "    count_by_load_area = candidates_gdf.groupby(\"LOAD_AREA\").size().reset_index(name=\"site_count\")\n",
    "\n",
    "    for i in range(1, 4):  \n",
    "        if i <= len(tech_names):\n",
    "            count_by_load_area[f\"prod_tech{i}\"] = tech_names[i-1]\n",
    "        else:\n",
    "            count_by_load_area[f\"prod_tech{i}\"] = \"\"\n",
    "\n",
    "\n",
    "    # Calculate reference capacity in MW (using 33.39 kg H2/MWh and truncating)\n",
    "    tech_ref_capacity_MW = int(ref_capacity / 24 * 33.39)\n",
    "\n",
    "    # Calculate total potential capacity in each load zone\n",
    "    count_by_load_area[\"potential_MW\"] = (\n",
    "        count_by_load_area[\"site_count\"] * tech_ref_capacity_MW\n",
    "    )\n",
    "\n",
    "    return count_by_load_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392c69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved technology capacity by load zone to /Users/nicholaskong/Desktop/REAM_lab/hydrogen_siting/technology_capacity_by_load_zone.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a running list of potential capacity\n",
    "output_df = pd.DataFrame()\n",
    "\n",
    "# Load final suitable candidate sites for each technology and calculate potential capacity by load zone\n",
    "for tech_file in final_output_path.glob(\"*.gpkg\"):\n",
    "    gdf = gpd.read_file(tech_file)\n",
    "\n",
    "    file_name = tech_file.stem\n",
    "    \n",
    "    if file_name == 'all_bio_smr_atr':\n",
    "        tech_names = ['bio_smr', 'bio_smr_ccs', 'bio_atr_ccs']\n",
    "    elif file_name == 'all_coal_gas':\n",
    "        tech_names = ['coal_gas', 'coal_gas_ccs']\n",
    "    elif file_name == 'all_gas_smr_atr':\n",
    "        tech_names = ['gas_smr', 'gas_smr_ccs', 'gas_atr_ccs']\n",
    "    elif file_name == 'biomass_gas':\n",
    "        tech_names = ['biomass_gas']\n",
    "    elif file_name == 'extra_bio_smr':\n",
    "        tech_names = ['bio_smr']\n",
    "    elif file_name == 'extra_coal_gas':\n",
    "        tech_names = ['coal_gas']\n",
    "    else:\n",
    "        raise Exception(f'tech name {file_name} not found')\n",
    "\n",
    "    nameplate_capacity = ref_capacity[tech_names[0]]\n",
    "\n",
    "    potential_df = calculate_potential(gdf, tech_names, nameplate_capacity)\n",
    "    \n",
    "    # Append to output DataFrame\n",
    "    output_df = pd.concat([output_df, potential_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# Sort \n",
    "output_df = output_df.sort_values(by=[\"LOAD_AREA\", \"prod_tech1\", \"prod_tech2\", \"prod_tech3\"])\n",
    "\n",
    "# Build the cartesian product of load areas × unique technology sets\n",
    "load_areas = load_zones_gdf[\"LOAD_AREA\"].unique()\n",
    "\n",
    "# Get unique tech sets (as tuples) from your output_df\n",
    "tech_sets = (\n",
    "    output_df[[\"prod_tech1\", \"prod_tech2\", \"prod_tech3\"]]\n",
    "    .drop_duplicates()\n",
    "    .apply(tuple, axis=1)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# Build MultiIndex product of load_areas × tech_sets\n",
    "all_combinations = pd.MultiIndex.from_product(\n",
    "    [load_areas, tech_sets],\n",
    "    names=[\"LOAD_AREA\", \"tech_set\"]\n",
    ").to_frame(index=False)\n",
    "\n",
    "# Expand the tuple back into columns\n",
    "all_combinations[[\"prod_tech1\", \"prod_tech2\", \"prod_tech3\"]] = pd.DataFrame(\n",
    "    all_combinations[\"tech_set\"].tolist(), index=all_combinations.index\n",
    ")\n",
    "all_combinations = all_combinations.drop(columns=\"tech_set\")\n",
    "\n",
    "# Merge with output_df on LOAD_AREA + all three prod_tech columns\n",
    "output_df = all_combinations.merge(\n",
    "    output_df,\n",
    "    on=[\"LOAD_AREA\", \"prod_tech1\", \"prod_tech2\", \"prod_tech3\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# Save\n",
    "output_csv_path = base_path.parent / \"technology_capacity_by_load_zone.csv\"\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Saved technology capacity by load zone to {output_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
